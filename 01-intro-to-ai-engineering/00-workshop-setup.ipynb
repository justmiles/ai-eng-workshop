{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0e2becb",
   "metadata": {},
   "source": [
    "## Workshop Setup\n",
    "\n",
    "To progress through this workshop we need to launch ollama and ensure the models we want to work with are downloaded. This container ships with the latest version of Ollama, but you need to launch the server. To do so\n",
    "\n",
    "- Select File -> New -> Terminal\n",
    "- Run the command: `ollama serve`\n",
    "- Launch a second terminal: File -> New -> Terminal\n",
    "- Run the command: `ollama pull driaforall/tiny-agent-a:0.5b`\n",
    "\n",
    "\n",
    "You can view the currently downloaded models with the command `ollama list`. View available models here: https://ollama.com/search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f04033e-b1a3-4e77-abd9-b361d6679b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8f51a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion\n",
    "\n",
    "model=\"ollama/driaforall/tiny-agent-a:0.5b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d44b54e-11eb-4e6f-a47f-42df2134868a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant. Reply only once as 'assistant' to the user's instruction. Do not invent conversations.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "]\n",
    "\n",
    "response = completion(model=model, messages=messages)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
